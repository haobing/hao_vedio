把图片1.jpg叠加到test.mp4视频的底部，命令如下：

ffmpeg -i test.mp4 -vf "movie=1.jpg,scale=480:120[watermask];[in][watermask] overlay=1:820[out]" -y out.mp4

参数解析：

-i test.mp4：输入文件是test.mp4；

movie=1.jpg ：需要叠加的图片是1.jpg；

scale=480:120：图片在视频中显示的宽高；

overlay=1:820：图片距视频左侧1个像素，距视频顶部820个像素；

out.mp4：新生成的视频名字是out.mp4；

-y：覆盖已有的生成文件。

#include "libavcodec/avcodec.h"
#include "libavformat/avformat.h"
#include "libavutil/pixfmt.h"
#include "libswscale/swscale.h"
#include "libavutil/opt.h"
#include "libavfilter/avfiltergraph.h"
#include "libavfilter/buffersink.h"
#include "libavfilter/buffersrc.h"

#include<stdio.h>

AVFilterContext *buffersink_ctx;
AVFilterContext *buffersrc_ctx;
AVFilterGraph *filter_graph;
//const char *filter_desrc = "drawtext=fontfile=/usr/share/fonts/lyx/eufm10.ttf:fontcolor=red:fontsize=30:text='Lei Xiaohuafdsfsdfsdf':x=50:y=50";
const char *filter_desrc = "movie=my_logo.png,scale=110:45[wm];[in][wm] overlay=5:5[out]";

int init_filters(const char *filters_descr,AVCodecContext *pCodecCtx)
{
    char args[512];
    int ret;
    AVFilter *buffersrc = avfilter_get_by_name("buffer");
    AVFilter *buffersink = avfilter_get_by_name("ffbuffersink");
    AVFilterInOut *outputs = avfilter_inout_alloc();
    AVFilterInOut *inputs = avfilter_inout_alloc();
    enum AVPixelFormat pix_fmts[] = {PIX_FMT_YUV420P,PIX_FMT_NONE};
    AVBufferSinkParams *buffersink_params;

    filter_graph = avfilter_graph_alloc();
    snprintf(args,sizeof(args),"video_size=%dx%d:pix_fmt=%d:time_base=%d/%d:pixel_aspect=%d/%d",
            pCodecCtx->width,pCodecCtx->height,pCodecCtx->pix_fmt,
            pCodecCtx->time_base.num,pCodecCtx->time_base.den,
            pCodecCtx->sample_aspect_ratio.num,pCodecCtx->sample_aspect_ratio.den);

    ret = avfilter_graph_create_filter(&buffersrc_ctx,buffersrc,"in",args,NULL,filter_graph);
    if(ret < 0)
    {
        printf("can't create filter buffer source\n");
        return -1;
    }

    buffersink_params = av_buffersink_params_alloc();
    buffersink_params->pixel_fmts = pix_fmts;
    ret = avfilter_graph_create_filter(&buffersink_ctx,buffersink,"out",NULL,buffersink_params,filter_graph);
    if(ret < 0)
    {
        printf("can't create buffer sink\n");
        return -1;
    }
    av_free(buffersink_params);

    outputs->name = av_strdup("in");
    outputs->filter_ctx = buffersrc_ctx;
    outputs->pad_idx = 0;
    outputs->next = NULL;

    inputs->name = av_strdup("out");
    inputs->filter_ctx = buffersink_ctx;
    inputs->pad_idx = 0;
    inputs->next = NULL;

    ret = avfilter_graph_parse_ptr(filter_graph,filters_descr,&inputs,&outputs,NULL);
    if(ret < 0)
    {
        printf("avfilter graph parse ptr error\n");
        return -1;
    }

    ret = avfilter_graph_config(filter_graph,NULL);
    if(ret < 0)
    {   
        printf("avfilter graph config error\n");
        return -1;
    }

    return 0;
}


int main()
{
    AVFormatContext *pFormatCtx;
    AVCodecContext *pCodecCtx;
    AVCodec *pCodec;
    AVFrame *Frame;
    AVFrame *Frame1;
    AVFrame *Frameout;
    AVPacket *packet;
    static struct SwsContext *img_convert_ctx;
    const char *file = "pra.mp4";
    int ret,i;
    int videoindex = 1;
    printf("fdfsssss**************************************\n");
    av_register_all();
    avfilter_register_all();
   pFormatCtx = avformat_alloc_context();
   
   ret = avformat_open_input(&pFormatCtx,file,NULL,NULL);
   if(ret < 0)
   {
       printf("avformat open input error\n");
       return -1;
   }

   ret = avformat_find_stream_info(pFormatCtx,NULL);
   if(ret < 0)
   {
       printf("avformat find stream info error\n");
       return -1;
   }

   for(i=0;i<pFormatCtx->nb_streams;i++)
   {
       if(pFormatCtx->streams[i]->codec->codec_type == AVMEDIA_TYPE_VIDEO)
       {
           videoindex = i;
           break;
       }
   }
   
   printf("the videoindex =%d\n",videoindex);

   pCodecCtx = pFormatCtx->streams[videoindex]->codec;
   pCodec = avcodec_find_decoder(pCodecCtx->codec_id);
   if(pCodec == NULL)
   {
       printf("codec can't find\n");
       return -1;
   }

   ret = avcodec_open2(pCodecCtx,pCodec,NULL);
   if(ret < 0)
   {
       printf("avcodec open error\n");
       return -1;
   }

    ret = init_filters(filter_desrc,pCodecCtx);
    if(ret < 0)
    {
        printf("init filters error\n");
        return -1;
    }

    Frame = av_frame_alloc();
    Frame1 = av_frame_alloc();
    Frameout = av_frame_alloc();

    img_convert_ctx = sws_getContext(pCodecCtx->width,pCodecCtx->height,
                     pCodecCtx->pix_fmt,pCodecCtx->width,pCodecCtx->height,
                     PIX_FMT_YUV420P,SWS_BICUBIC,NULL,NULL,NULL);
    
    int numsize = avpicture_get_size(PIX_FMT_YUV420P,pCodecCtx->width,pCodecCtx->height);
    unsigned char *outbuff = (unsigned char*)av_malloc(numsize);
    ret = avpicture_fill((AVPicture*)Frameout,outbuff,PIX_FMT_YUV420P,
                        pCodecCtx->width,pCodecCtx->height);
    int ysize = pCodecCtx->width*pCodecCtx->height;

    packet = (AVPacket*)av_malloc(sizeof(AVPicture));
    //av_new_packet(packet,ysize);
    av_dump_format(pFormatCtx,0,file,0);
    char *outfile = "test.yuv";
    FILE *fp = fopen(outfile,"wb+");
    int got_picture = 0;
    while(1)
    {
        if(av_read_frame(pFormatCtx,packet)<0)
        {
            break;
        }
        if(packet->stream_index == videoindex)
        {   
            ret = avcodec_decode_video2(pCodecCtx,Frame,&got_picture,packet);
            if(ret < 0)
            {
                printf("avcodec decode video2 error\n");
                break;
            }

            if(got_picture)
            {  
                Frame->pts = av_frame_get_best_effort_timestamp(Frame);
                 ret = av_buffersrc_add_frame(buffersrc_ctx,Frame);
                if(ret <0)
                {
                    printf("error while feeding the filtergraph\n");
                    break;
                }
                ret = av_buffersink_get_frame(buffersink_ctx,Frame1);
                if(ret < 0)
                {
                    break;
                }

                sws_scale(img_convert_ctx,(unsigned char const *const *)Frame1->data,
                Frame1->linesize,0,pCodecCtx->height,Frameout->data,Frameout->linesize);

             
                fwrite(Frameout->data[0],1,ysize,fp);
                fwrite(Frameout->data[1],1,ysize/4,fp);
                fwrite(Frameout->data[2],1,ysize/4,fp);
            }

        }
        av_free_packet(packet);
    }
    av_free(outbuff);
    av_free(Frameout);
    avcodec_close(pCodecCtx);
    avformat_close_input(&pFormatCtx);
    return 0;
}
