.mp4文件-读取流-解码出YUV图片-转为RGB-保存
#include "libavcodec/avcodec.h"
#include "libavformat/avformat.h"
#include "libavutil/pixfmt.h"
#include "libswscale/swscale.h"
#include<stdio.h>
void SaveFrame(AVFrame *pFrame, int width, int height,int index)
{

  FILE *pFile;
  char szFilename[32];
  int  y;

  // Open file
  sprintf(szFilename, "frame%d.ppm", index);
  pFile=fopen(szFilename, "wb");

  if(pFile==NULL)
    return;

  // Write header
  fprintf(pFile, "P6\n%d %d\n255\n", width, height);

  // Write pixel data
  for(y=0; y<height; y++)
  {
      //每个像素3个字节，一次写入一行的像素数据
    fwrite(pFrame->data[0]+y*pFrame->linesize[0], 1, width*3, pFile);
  }

  // Close file
  fclose(pFile);

}


int main(int argc, char *argv[])
{
    char *file_path = "pra.mp4";

    AVFormatContext *pFormatCtx;
    AVCodecContext *pCodecCtx;
    AVCodec *pCodec;
    AVFrame *pFrame, *pFrameRGB;
    AVPacket *packet;
    uint8_t *out_buffer;

    static struct SwsContext *img_convert_ctx;

    int videoStream, i, numBytes;
    int ret, got_picture;

    av_register_all(); //初始化FFMPEG  调用了这个才能正常适用编码器和解码器

    //Allocate an AVFormatContext.
    pFormatCtx = avformat_alloc_context();

    if (avformat_open_input(&pFormatCtx, file_path, NULL, NULL) != 0) {
        printf("can't open the file. \n");
        return -1;
    }

    if (avformat_find_stream_info(pFormatCtx, NULL) < 0) {
        printf("Could't find stream infomation.\n");
        return -1;
    }

    videoStream = -1;

    ///循环查找视频中包含的流信息，直到找到视频类型的流
    ///便将其记录下来 保存到videoStream变量中
    ///这里我们现在只处理视频流  音频流先不管他
    for (i = 0; i < pFormatCtx->nb_streams; i++) {
        if (pFormatCtx->streams[i]->codec->codec_type == AVMEDIA_TYPE_VIDEO) {
            videoStream = i;
        }
    }
    printf("nb_streams is %d\n",pFormatCtx->nb_streams);

    ///如果videoStream为-1 说明没有找到视频流
    if (videoStream == -1) {
        printf("Didn't find a video stream.\n");
        return -1;
    }

    ///查找解码器
    pCodecCtx = pFormatCtx->streams[videoStream]->codec;
    pCodec = avcodec_find_decoder(pCodecCtx->codec_id);

    if (pCodec == NULL) {
        printf("Codec not found.\n");
        return -1;
    }

    ///打开解码器
    if (avcodec_open2(pCodecCtx, pCodec, NULL) < 0) {
        printf("Could not open codec.\n");
        return -1;
    }


//分配内存给视频信息描述结构体


    pFrame = av_frame_alloc();
    pFrameRGB = av_frame_alloc();
    //* Allocate and return an SwsContext. You need it to perform
    //* scaling/conversion operations using sws_scale().
    img_convert_ctx = sws_getContext(pCodecCtx->width, pCodecCtx->height,
            pCodecCtx->pix_fmt, pCodecCtx->width, pCodecCtx->height,
            AV_PIX_FMT_RGB24, SWS_BICUBIC, NULL, NULL, NULL);

//计算视频一幅图像的大小
    numBytes = avpicture_get_size(AV_PIX_FMT_RGB24, pCodecCtx->width,pCodecCtx->height);

//给一幅图像分配内存
    out_buffer = (uint8_t *) av_malloc(numBytes * sizeof(uint8_t));

    avpicture_fill((AVPicture *) pFrameRGB, out_buffer, AV_PIX_FMT_RGB24,
            pCodecCtx->width, pCodecCtx->height);
//计算一幅图像的尺寸，像素多少
    int y_size = pCodecCtx->width * pCodecCtx->height;
   // For video, it should typically contain one compressed frame. For audio it may
   // * contain several compressed frames. 为一帧编码的原始视频数据分配内存
//packet中保存的是一帧图像数据
    packet = (AVPacket *) malloc(sizeof(AVPacket)); //分配一个packet
    av_new_packet(packet, y_size); //分配packet的数据

    av_dump_format(pFormatCtx, 0, file_path, 0); //输出视频信息

    int index = 0;

    while (1)
    {
        //读取一帧数据，放入packet
        if (av_read_frame(pFormatCtx, packet) < 0)
        {
            break; //这里认为视频读取完了
        }

        if (packet->stream_index == videoStream) {
            //解码的YUV数据存放在pFrame中
            ret = avcodec_decode_video2(pCodecCtx, pFrame, &got_picture,packet);

            if (ret < 0) {
                printf("decode error.\n");
                return -1;
            }
            //如果有数据解码出来
            if (got_picture) {
                //数据保存在pFrameRGB中
                sws_scale(img_convert_ctx,
                        (uint8_t const * const *) pFrame->data,
                        pFrame->linesize, 0, pCodecCtx->height, pFrameRGB->data,
                        pFrameRGB->linesize);
                //把pFrameRGB中的数据保存到文件中
                SaveFrame(pFrameRGB, pCodecCtx->width,pCodecCtx->height,index++); //保存图片
                if (index > 50) return 0; //这里我们就保存50张图片
            }
        }
        av_free_packet(packet);
    }
    av_free(out_buffer);
    av_free(pFrameRGB);
    avcodec_close(pCodecCtx);
    avformat_close_input(&pFormatCtx);

    return 0;
}

保存为YUV--------------------------------------------------------------------------------------------------------------

#include "libavcodec/avcodec.h"
#include "libavformat/avformat.h"
#include "libavutil/pixfmt.h"
#include "libswscale/swscale.h"
#include<stdio.h>
void write_frame(AVFrame *frame,FILE *fp)
{
    for (int i = 0; i < frame->height; i++)
    {
        fwrite(frame->data[0] + frame->linesize[0] * i, 1, frame->width, fp);
    }

    for (int i = 0; i < frame->height / 2; i++)
    {
        fwrite(frame->data[1] + frame->linesize[1] * i, 1, frame->width / 2, fp);
    }

    for (int i = 0; i < frame->height / 2; i++)
    {
        fwrite(frame->data[2] + frame->linesize[2] * i, 1, frame->width / 2, fp);
    }
}

int main()
{
AVFormatContext *pFormatCtx;
int i,videoindex = -1;
AVCodecContext *pCodecCtx;
AVCodec *pCodec;
AVFrame *pFrame,*pFrameYUV;
AVPacket *packet;
unsigned char *buf;
struct SwsContext *img_convert_ctx;
FILE *file;
char *path ="pra.mp4";
int ret,got_picture;

av_register_all();

pFormatCtx = avformat_alloc_context();
avformat_network_init();
if(avformat_open_input(&pFormatCtx,path,NULL,NULL)!=0)
{
    printf("avformat_open_input error\n");
    return -1;
}
ret =avformat_find_stream_info(pFormatCtx,NULL);
if(ret<0)
{
    printf("avformat_find_stream_info error\n");
    return -1;
}

for(i=0; i<pFormatCtx->nb_streams;i++)
{
    if(pFormatCtx->streams[i]->codec->codec_type == AVMEDIA_TYPE_VIDEO)
    {
        videoindex = i;
        break;
    }
}

if(videoindex == -1)
{
    printf("can't find a video stream\n");
    return -1;
}

pCodecCtx = pFormatCtx->streams[videoindex]->codec;
pCodec = avcodec_find_decoder(pCodecCtx->codec_id);
if(pCodec == NULL)
{
    printf("can't find a decoder\n");
    return -1;
}
printf("the pCodecCtx->time_base.den=%d\n",pCodecCtx->time_base.den);
ret = avcodec_open2(pCodecCtx,pCodec,NULL);
if(ret < 0)
{
    printf("can't open codec\n");
    return -1;
}

pFrame = av_frame_alloc();
pFrameYUV = av_frame_alloc();

int numbyte = avpicture_get_size(PIX_FMT_YUV420P,pCodecCtx->width,pCodecCtx->height);
buf = (unsigned char *)av_malloc(numbyte);
avpicture_fill((AVPicture*)pFrameYUV,buf,PIX_FMT_YUV420P,pCodecCtx->width,pCodecCtx->height);

int ysize = pCodecCtx->width*pCodecCtx->height;

packet = (AVPacket *)av_malloc(sizeof(AVPacket));
//av_new_packet(packet,ysize);
av_dump_format(pFormatCtx,0,path,0);

img_convert_ctx = sws_getContext(pCodecCtx->width,pCodecCtx->height,pCodecCtx->pix_fmt,pCodecCtx->width,pCodecCtx->height,PIX_FMT_YUV420P,SWS_BICUBIC, NULL, NULL, NULL);
file = fopen("outputs.yuv","wb");
while((ret = av_read_frame(pFormatCtx,packet))>=0)
{
    if(packet->stream_index == videoindex)
    {   printf("***********\n");
        ret = avcodec_decode_video2(pCodecCtx,pFrame,&got_picture,packet);
        if(ret<0)
        {
            printf("decode error\n");
            return -1;
        }
        printf("got_pictuer =%d",got_picture);
        if(got_picture)
        {   
           //write_frame(pFrame,file);
            #if 1
            sws_scale(img_convert_ctx,(unsigned char const* const*)pFrame->data,pFrame->linesize,0,pCodecCtx->height,pFrameYUV->data,pFrameYUV->linesize);
            int y_size = pCodecCtx->width*pCodecCtx->height;
            #if 0
            fprintf(file,"P6\n%d %d\n255\n",pCodecCtx->width,pCodecCtx->height);
            int y;
            for(y=0;y<pCodecCtx->height;y++)
            {
                fwrite(pFrameYUV->data[0]+y*pFrameYUV->linesize[0],1,pCodecCtx->width*3,file);
            }
            break;
            #endif
            #if 1
            fwrite(pFrameYUV->data[0],1,y_size,file);
            fwrite(pFrameYUV->data[1],1,y_size/4,file);
            fwrite(pFrameYUV->data[2],1,y_size/4,file);
            break;
            #endif
            #endif
        }
    }
    av_free_packet(packet);
}
printf("the ret =%d index =%d\n",ret,videoindex);
    av_free(pFrameYUV);
	avcodec_close(pCodecCtx);
	avformat_close_input(&pFormatCtx);
}



#if 0
使用ffmpeg步骤
av_register_all();//初始化ffmpeg库，如果系统里面的ffmpeg没配置好这里会出错
 if (isNetwork) {
     //需要播放网络视频
     avformat_network_init();
 }
 avformat_open_input();//打开视频文件
 avformat_find_stream_info();//查找文件的流信息
 av_dump_format();//dump只是个调试函数，输出文件的音、视频流的基本信息了，帧率、分辨率、音频采样等等
 for(...);//遍历文件的各个流，找到第一个视频流，并记录该流的编码信息
 sws_getContext();//根据编码信息设置渲染格式
 avcodec_find_decoder();//在库里面查找支持该格式的解码器
 avcodec_open2();//打开解码器
 pFrame=avcodec_alloc_frame();//分配一个帧指针，指向解码后的原始帧
 pFrameRGB=avcodec_alloc_frame();//分配一个帧指针，指向存放转换成RGB后的帧
 avpicture_fill(pFrameRGB);//给pFrameRGB帧加上分配的内存;
 while(true)
 {
     av_read_frame();//读取一个帧（到最后帧则break）
     avcodec_decode_video2();//解码该帧
     sws_getCachedContext()sws_scale（）;//把该帧转换（渲染）成RGB
     SaveFrame();//对前5帧保存成ppm图形文件(这个是自定义函数，非API)
     av_free_packet();//释放本次读取的帧内存
 }
 #endif
